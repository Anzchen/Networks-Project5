#!/usr/bin/env python3

import argparse
import re
import socket
import ssl
from html.parser import HTMLParser

DEFAULT_SERVER = "proj5.3700.network"
DEFAULT_PORT = 443


class LinkParser(HTMLParser):
    def __init__(self):
        super().__init__()
        self.links = []

    def handle_starttag(self, tag, attrs):
        if tag == 'a':
            for attr in attrs:
                if attr[0] == 'href':
                    self.links.append(attr[1])


class Crawler:
    def __init__(self, args):
        self.server = args.server
        self.port = args.port
        self.username = args.username
        self.password = args.password
        self.notVisited = []
        self.visited = set()
        self.secret_flags = set()

    def create_socket(self):
        mysocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        mysocket.connect((self.server, self.port))
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = False
        ssl_context.verify_mode = ssl.CERT_NONE
        mysocket = ssl_context.wrap_socket(mysocket, server_hostname=self.server)
        return mysocket

    def send_request(self, request, mysocket):
        mysocket.send(request.encode('ascii'))
        data = b""
        try:
            while True:
                recv_data = mysocket.recv(1000)
                if not recv_data:
                    break
                data += recv_data
                if b'</html>' in recv_data or b'Location' in recv_data:
                    break
        except socket.timeout:
            print("Socket timeout reached, return current data:")
            print(data.decode('ascii'))
            return data.decode('ascii')
        return data.decode('ascii')

    def run(self):
        request = f"GET /accounts/login/ HTTP/1.1\r\nHost: {self.server}\r\nConnection: close\r\n\r\n"
        mysocket = self.create_socket()
        data = self.send_request(request, mysocket)
        mysocket.close()

        # Find and get the CSRF token
        csrfPos = data.find('csrfmiddlewaretoken')
        csrfVal = data.find('value', csrfPos + 1)
        csrf = data[csrfVal + 7: csrfVal + 39]

        login_request = f"POST /accounts/login/ HTTP/1.1\r\nHost: {self.server}\r\nConnection: close\r\nContent-Length: 109\r\nContent-Type: application/x-www-form-urlencoded\r\nCookie: csrftoken={csrf};\r\n\r\nusername={self.username}&password={self.password}&csrfmiddlewaretoken={csrf}&next=%2Ffakebook%2F"
        mysocket = self.create_socket()
        data = self.send_request(login_request, mysocket)
        mysocket.close()

        # Find and get session ID
        SessionPos = data.find("sessionid=")
        sessionID = data[SessionPos + 10:SessionPos + 42]

        self.notVisited.append(f"https://{self.server}/fakebook/")

        while len(self.secret_flags) < 5 and len(self.notVisited) > 0:
            page = self.notVisited.pop()
            if page not in self.visited:
                self.visited.add(page)
                nextPage = f"GET {page} HTTP/1.1\r\nHost: {self.server}\r\nConnection: close\r\nCookie: csrftoken={csrf};sessionid={sessionID};\r\n\r\n"
                mysocket = self.create_socket()
                data = self.send_request(nextPage, mysocket)
                mysocket.close()

                status = re.findall(r"\D(\d{3})\D", data)

                if status[0] == '200':
                    # Handle 200 - OK
                    flags = re.findall(r"FLAG: (\w{64})", data)
                    for flag in flags:
                        self.secret_flags.add(flag)
                    parser = LinkParser()
                    parser.feed(data)
                    new_links = [f"https://{self.server}{link}" for link in parser.links if
                                 f"https://{self.server}{link}" not in self.visited
                                 and f"https://{self.server}{link}" not in self.notVisited]
                    for link in new_links:
                        self.notVisited.append(link)
                    self.visited.add(page)

                elif status[0] == '302':
                    # Handle 302 - Found (Redirect)
                    location = re.search(r"Location: (.*)\r\n", data)
                    if location:
                        new_url = location.group(1)
                        if new_url.startswith("/"):
                            new_url = f"https://{self.server}{new_url}"
                        if new_url.startswith(f"https://{self.server}/fakebook/"):
                            self.notVisited.append(new_url)

                elif status[0] in ('403', '404'):
                    # Handle 403 - Forbidden and 404 - Not Found
                    # Do nothing, just abandon the URL
                    pass

                elif status[0] == '503':
                    # Handle 503 - Service Unavailable
                    # Re-try the request by adding the URL back to self.notVisited
                    self.notVisited.append(page)

        # After the while loop, print the found secret flags
        for flag in self.secret_flags:
            print(flag)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='crawl Fakebook')
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()
    sender = Crawler(args)
    sender.run()
